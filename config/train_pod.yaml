apiVersion: batch/v1
kind: Job
metadata:
  name: vae-pneumonia-train-job
spec:
  backoffLimit: 2  # Retry up to 2 times if the job fails
  ttlSecondsAfterFinished: 86400  # Auto-delete job after 24 hours of completion
  template:
    metadata:
      labels:
        app: vae-pneumonia-train-app
    spec:
      containers:
      - name: gpu-container
        image: timttu/vae-pneumonia:v5
        command: ["/bin/bash", "-c"]
        args: [
          "set -e && \
          apt-get update && apt-get install -y unzip && \
          pip3 install 'numpy<2.0' gdown --force-reinstall jupyterlab && \
          git config --global credential.helper store && \
          echo \"https://oauth2:${GIT_ACCESS_TOKEN}@github.com\" > ~/.git-credentials && \
          cd /mnt/tim && \
          if [ ! -d 'VAE_for_Pneumonia' ]; then \
            echo 'Cloning VAE_for_Pneumonia repository...' && \
            git clone https://github.com/timtutu2/VAE_for_Pneumonia.git VAE_for_Pneumonia ; \
          else \
            echo 'Repository exists, updating...' && \
            cd VAE_for_Pneumonia && \
            git fetch origin && \
            git pull origin master ; \
          fi && \
          echo 'Repository cloned/updated. Starting training...' && \
          cd /mnt/tim/VAE_for_Pneumonia && \
          mkdir -p logs && \
          LOGFILE=logs/train_pneumonia_VAE_$(date +%Y%m%d_%H%M%S).log && \
          echo \"Saving logs to $LOGFILE\" && \
          python train.py --config ./config/train_config.yaml 2>&1 | tee $LOGFILE && \
          echo \"Training started. Logs will be saved to $LOGFILE\""
        ]
        env:
        - name: AUTO_MODE
          value: "true"
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: wandb-tim-secret 
              key: api_key
        - name: GIT_ACCESS_TOKEN
          valueFrom:
            secretKeyRef:
              name: github--token
              key: GIT_ACCESS_TOKEN
        volumeMounts:
        - mountPath: /mnt
          name: erl-ucsd
        - mountPath: /dev/shm
          name: dshm
        resources:
          limits:
            nvidia.com/gpu: "2"
            memory: "64G"
            cpu: "8"
          requests:
            nvidia.com/gpu: "2"
            memory: "64G"
            cpu: "8"
      restartPolicy: OnFailure  # Retry on failure, but not on success
      affinity:
        nodeAffinity:
          # Exclude nodes with CSI driver issues
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                - "k8s-haosu-04.sdsc.optiputer.net"
                - "ry-gpu-14.sdsc.optiputer.net"
          preferredDuringSchedulingIgnoredDuringExecution:
          # Empirically determined nodes with good network to download large docker images
          - weight: 100
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "ry-gpu-01.sdsc.optiputer.net"
                - "ry-gpu-02.sdsc.optiputer.net"
                - "ry-gpu-03.sdsc.optiputer.net"
                - "ry-gpu-04.sdsc.optiputer.net"
                - "ry-gpu-05.sdsc.optiputer.net"
                - "ry-gpu-06.sdsc.optiputer.net"
                - "ry-gpu-07.sdsc.optiputer.net"
                - "ry-gpu-08.sdsc.optiputer.net"
                - "ry-gpu-09.sdsc.optiputer.net"
                - "ry-gpu-10.sdsc.optiputer.net"
                - "ry-gpu-11.sdsc.optiputer.net"
                - "ry-gpu-12.sdsc.optiputer.net"
                - "ry-gpu-13.sdsc.optiputer.net"
                - "ry-gpu-14.sdsc.optiputer.net"
                - "ry-gpu-15.sdsc.optiputer.net"
                - "ry-gpu-16.sdsc.optiputer.net"
                - "k8s-3090-01.calit2.optiputer.net"
                - "k8s-4090-01.calit2.optiputer.net"
                - "k8s-4090-02.calit2.optiputer.net"
          - weight: 50
            preference:
              matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - "k8s-haosu-02.sdsc.optiputer.net"
                - "k8s-haosu-03.sdsc.optiputer.net"
                - "k8s-haosu-04.sdsc.optiputer.net"
                - "k8s-haosu-05.sdsc.optiputer.net"
                - "k8s-haosu-06.sdsc.optiputer.net"
                - "k8s-haosu-07.sdsc.optiputer.net"
                - "k8s-haosu-08.sdsc.optiputer.net"
                - "k8s-haosu-09.sdsc.optiputer.net"
                - "k8s-haosu-10.sdsc.optiputer.net"
                - "k8s-haosu-11.sdsc.optiputer.net"
                - "k8s-haosu-12.sdsc.optiputer.net"
                - "k8s-haosu-13.sdsc.optiputer.net"
                - "k8s-haosu-14.sdsc.optiputer.net"
                - "k8s-haosu-15.sdsc.optiputer.net"
                - "k8s-haosu-16.sdsc.optiputer.net"
                - "k8s-haosu-17.sdsc.optiputer.net"
                - "k8s-haosu-18.sdsc.optiputer.net"
                - "k8s-haosu-19.sdsc.optiputer.net"
                - "k8s-haosu-20.sdsc.optiputer.net"
                - "k8s-haosu-21.sdsc.optiputer.net"
                - "k8s-haosu-22.sdsc.optiputer.net"
                - "k8s-haosu-23.sdsc.optiputer.net"
          - weight: 80
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A100-80GB-PCIe"
                - "NVIDIA-A100-SXM4-80GB"
                - "NVIDIA-A100-80GB-PCIe-MIG-1g.10gb"
                - "NVIDIA-A100-PCIE-40GB"
                - "NVIDIA-RTX-A6000"
                - "NVIDIA-RTX-A5000"
                - "NVIDIA-GeForce-RTX-4090"
                - "NVIDIA-GeForce-RTX-4080"
                - "NVIDIA-GeForce-RTX-3090-Ti"
                - "NVIDIA-GeForce-RTX-3090"
                - "NVIDIA-GeForce-RTX-3080-Ti"
                - "NVIDIA-GeForce-RTX-3080"
          - weight: 60
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-A40"
                - "Tesla-V100-SXM2-32GB"
                - "Tesla-V100-PCIE-16GB"
          - weight: 50
            preference:
              matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - "NVIDIA-TITAN-RTX"
                - "NVIDIA-GeForce-RTX-2080-Ti"
                - "NVIDIA-TITAN-Xp"
                - "NVIDIA-L40"
                - "NVIDIA-A10"
      volumes:
        - name: erl-ucsd
          persistentVolumeClaim:
            claimName: erl-ucsd
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 8Gi
